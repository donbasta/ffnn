{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar IF 3270 Pembelajaran Mesin\n",
    "Dikumpulkan: Jumat, 5 Maret 2021 jam 23.55\n",
    "\n",
    "Dibuat oleh\n",
    "Kelompok **Neuron Activation**\n",
    "* Farras Mohammad Hibban Faddila - K2 - 13518017\n",
    "* Jun Ho Choi Hedyatmo - K2 - 13518044\n",
    "* Moch. Nafkhan Alzamzami - K3 - 13518132\n",
    "* Michel Fang - K2 - 13518137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagian A: Implementasi Forward Propagation untuk Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi Aktivasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi aktivasi yang dikenali adalah linear, sigmoid, ReLU, dan softmax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # applying the sigmoid function\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    # computing derivative to the Sigmoid function\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    # compute relu\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(x):\n",
    "    return np.where(x <= 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_derivative(x):\n",
    "    return np.full(x.shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    return ex / np.sum(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pemilihan Fungsi Aktivasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_functions = {\n",
    "    # activation_functions\n",
    "    \"relu\": relu,\n",
    "    \"sigmoid\": sigmoid,\n",
    "    \"softmax\": softmax,\n",
    "    \"linear\": linear\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setiap layer dibatasi memiliki neuron dengan fungsi aktivasi yang sama, namun antar layer diperbolehkan memiliki neuron dengan aktivasi yang berbeda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, activation, input, output):\n",
    "        self.activation_name = activation\n",
    "        self.activation = activation_functions[activation]\n",
    "        self.W = np.zeros((output, input))\n",
    "        self.b = np.zeros((output, 1))\n",
    "\n",
    "    def set_weight(self, weight):\n",
    "        self.W = weight\n",
    "\n",
    "    def set_bias(self, bias):\n",
    "        self.b = bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class NeuralNetwork\n",
    "Konvensi nama method dibuat mirip dengan library machine learning pada umumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # seeding for random number generation\n",
    "        np.random.seed(1)\n",
    "        # converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
    "        self.layers = []\n",
    "        self.depth = 0\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.depth += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membaca dan menyimpan model FFNN\n",
    "Input dan output adalah sebuah file yang nama filenya `filename`.\n",
    "\n",
    "Format data model adalah\n",
    "```\n",
    "<depth>\n",
    "<n_neuron>\n",
    "(for every neuron)\n",
    "<activation_type>\n",
    "a11 a12 a13 (weights)\n",
    "a21 a22 a23\n",
    "b1 b2 (bias)\n",
    "```\n",
    "\n",
    "Contoh:\n",
    "```\n",
    "1\n",
    "2\n",
    "sigmoid\n",
    "a11 a12 a13\n",
    "a21 a22 a23\n",
    "b1 b2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def load_model(self, filename):\n",
    "        f = open(filename, \"r\")\n",
    "\n",
    "        self.depth = int(f.readline())\n",
    "\n",
    "        for i in range(self.depth):\n",
    "\n",
    "            n_neuron = int(f.readline())\n",
    "            activation_type = f.readline()[:-1]\n",
    "            weight = []\n",
    "\n",
    "            n_neuron_prev = -1\n",
    "            for j in range(n_neuron):\n",
    "                temp = list(map(float, f.readline().split()))\n",
    "                weight.append(temp)\n",
    "                if (n_neuron_prev == -1):\n",
    "                    n_neuron_prev = len(temp)\n",
    "\n",
    "            layer = Layer(activation_type, n_neuron_prev, n_neuron)\n",
    "            layer.set_weight(np.array(weight))\n",
    "            bias = np.array(\n",
    "                list(map(lambda x: [float(x)], f.readline().split())))\n",
    "            layer.set_bias(bias)\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        f = open(filename, \"w\")\n",
    "\n",
    "        f.write(str(self.depth) + \"\\n\")\n",
    "        for layer in self.layers:\n",
    "            n_neuron = len(layer.b)\n",
    "            f.write(str(n_neuron) + \"\\n\")\n",
    "            f.write(layer.activation_name + \"\\n\")\n",
    "            for i in range(n_neuron):\n",
    "                f.write(\" \".join(list(map(str, layer.W[i]))) + \"\\n\")\n",
    "            f.write(\n",
    "                \" \".join(list(map(lambda x: str(x[0]), layer.b))) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def forward_propagate(self, x_inputs):\n",
    "        a = np.array(x_inputs).T\n",
    "        for layer in self.layers:\n",
    "            z = np.dot(layer.W, a) + layer.b\n",
    "            a = layer.activation(z)\n",
    "        return a\n",
    "\n",
    "    def backward_propagate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dan prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def fit(self, x_train, y_train, training_iterations):\n",
    "        # training the model to make accurate predictions while adjusting weights continually\n",
    "        for iteration in range(training_iterations):\n",
    "            # siphon the training data via the neuron\n",
    "            prediction = self.forward_propagate(x_train)\n",
    "            # cost_function = error(prediction, y_train)\n",
    "            self.backward_propagate()\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        prediction = self.forward_propagate(x_test)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menampilkan model dengan struktur dan koefisien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def __str__(self):\n",
    "        index = 1\n",
    "        res = \"\"\n",
    "        for layer in self.layers:\n",
    "            res += \"{}-th layer\\n\".format(index)\n",
    "            res += f\"Activation: {layer.activation_name}\\n\"\n",
    "            res += \"Weight matrix:\\n\"\n",
    "            res += layer.W.__str__() + \"\\n\"\n",
    "            res += \"Bias\\n\"\n",
    "            res += layer.b.__str__() + \"\\n\\n\"\n",
    "            index += 1\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data XOR\n",
    "Data berikut diambil dari slide kuliah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = [[0, 0], [0, 1], [1, 0], [1, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model XOR Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th layer\n",
      "Activation: sigmoid\n",
      "Weight matrix:\n",
      "[[ 20.  20.]\n",
      " [-20. -20.]]\n",
      "Bias\n",
      "[[-10.]\n",
      " [ 30.]]\n",
      "\n",
      "2-th layer\n",
      "Activation: sigmoid\n",
      "Weight matrix:\n",
      "[[20. 20.]]\n",
      "Bias\n",
      "[[-30.]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xor_model = NeuralNetwork()\n",
    "xor_model.load_model(\"xor-sigmoid.txt\")\n",
    "print(xor_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediksi Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.54391049e-05, 9.99954520e-01, 9.99954520e-01, 4.54391049e-05]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_model.predict(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model XOR ReLU & Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th layer\n",
      "Activation: relu\n",
      "Weight matrix:\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Bias\n",
      "[[ 0.]\n",
      " [-1.]]\n",
      "\n",
      "2-th layer\n",
      "Activation: linear\n",
      "Weight matrix:\n",
      "[[ 1. -2.]]\n",
      "Bias\n",
      "[[0.]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relu_linear_model = NeuralNetwork()\n",
    "relu_linear_model.load_model(\"xor-relu-linear.txt\")\n",
    "print(relu_linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediksi ReLU & Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_linear_model.predict(DATA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}